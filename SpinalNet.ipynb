{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R8_SYWhzroVE"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import random\n",
        "import copy\n",
        "import imageio\n",
        "import time\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from torchvision import datasets, models, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision.datasets import ImageFolder\n",
        "from torch.utils.data import DataLoader, Subset, random_split\n",
        "from __future__ import print_function, division\n",
        "from torch.optim import lr_scheduler\n",
        "from sklearn.model_selection import StratifiedShuffleSplit\n",
        "from sklearn.utils.class_weight import compute_class_weight"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.Resize((256, 256)),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "dataset_path = \"/content/drive/MyDrive/Pre_processing/train\"\n",
        "dataset = ImageFolder(root=dataset_path, transform=transform)\n",
        "\n",
        "labels = [label for _, label in dataset.samples]\n",
        "\n",
        "sss = StratifiedShuffleSplit(n_splits=10, test_size=0.1, random_state=0)\n",
        "\n",
        "train_idx, val_idx = next(sss.split(labels, labels))\n",
        "\n",
        "train_dataset = Subset(dataset, train_idx)\n",
        "val_dataset = Subset(dataset, val_idx)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=128, shuffle=False)\n",
        "all_loader = DataLoader(dataset, batch_size=128, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FhyF7tfLnFMG",
        "outputId": "ee7c89bb-9528-413c-fba3-e38c16b5d106"
      },
      "outputs": [],
      "source": [
        "model_ft = models.wide_resnet101_2(pretrained=True)\n",
        "num_ftrs = model_ft.fc.in_features\n",
        "# model_ft.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
        "half_in_size = round(num_ftrs/2)\n",
        "layer_width = 1024\n",
        "Num_class=2\n",
        "\n",
        "# Customizable SpinalNet. Supports up to 30 layers.\n",
        "# model_ft.fc = SpinalNet(Input_Size = num_ftrs, Number_of_Split =2, HL_width=512, number_HL=10, Output_Size=2, Activation_Function = nn.ReLU(inplace=True))\n",
        "class SpinalNet(nn.Module):\n",
        "    def __init__(self, Input_Size, Number_of_Split, HL_width, number_HL, Output_Size, Activation_Function):\n",
        "\n",
        "        super(SpinalNet, self).__init__()\n",
        "        Splitted_Input_Size = int(np.round(Input_Size/Number_of_Split))\n",
        "        self.lru = Activation_Function\n",
        "        self.fc1 = nn.Linear(Splitted_Input_Size, HL_width)\n",
        "        if number_HL>1:\n",
        "            self.fc2 = nn.Linear(Splitted_Input_Size+HL_width, HL_width)\n",
        "        if number_HL>2:\n",
        "            self.fc3 = nn.Linear(Splitted_Input_Size+HL_width, HL_width)\n",
        "        if number_HL>3:\n",
        "            self.fc4 = nn.Linear(Splitted_Input_Size+HL_width, HL_width)\n",
        "        if number_HL>4:\n",
        "            self.fc5 = nn.Linear(Splitted_Input_Size+HL_width, HL_width)\n",
        "        if number_HL>5:\n",
        "            self.fc6 = nn.Linear(Splitted_Input_Size+HL_width, HL_width)\n",
        "        if number_HL>6:\n",
        "            self.fc7 = nn.Linear(Splitted_Input_Size+HL_width, HL_width)\n",
        "        if number_HL>7:\n",
        "            self.fc8 = nn.Linear(Splitted_Input_Size+HL_width, HL_width)\n",
        "        if number_HL>8:\n",
        "            self.fc9 = nn.Linear(Splitted_Input_Size+HL_width, HL_width)\n",
        "        if number_HL>9:\n",
        "            self.fc10 = nn.Linear(Splitted_Input_Size+HL_width, HL_width)\n",
        "        if number_HL>10:\n",
        "            self.fc11 = nn.Linear(Splitted_Input_Size+HL_width, HL_width)\n",
        "        if number_HL>11:\n",
        "            self.fc12 = nn.Linear(Splitted_Input_Size+HL_width, HL_width)\n",
        "        if number_HL>12:\n",
        "            self.fc13 = nn.Linear(Splitted_Input_Size+HL_width, HL_width)\n",
        "        if number_HL>13:\n",
        "            self.fc14 = nn.Linear(Splitted_Input_Size+HL_width, HL_width)\n",
        "        if number_HL>14:\n",
        "            self.fc15 = nn.Linear(Splitted_Input_Size+HL_width, HL_width)\n",
        "        if number_HL>15:\n",
        "            self.fc16 = nn.Linear(Splitted_Input_Size+HL_width, HL_width)\n",
        "        if number_HL>16:\n",
        "            self.fc17 = nn.Linear(Splitted_Input_Size+HL_width, HL_width)\n",
        "        if number_HL>17:\n",
        "            self.fc18 = nn.Linear(Splitted_Input_Size+HL_width, HL_width)\n",
        "        if number_HL>18:\n",
        "            self.fc19 = nn.Linear(Splitted_Input_Size+HL_width, HL_width)\n",
        "        if number_HL>19:\n",
        "            self.fc20 = nn.Linear(Splitted_Input_Size+HL_width, HL_width)\n",
        "        if number_HL>20:\n",
        "            self.fc21 = nn.Linear(Splitted_Input_Size+HL_width, HL_width)\n",
        "        if number_HL>21:\n",
        "            self.fc22 = nn.Linear(Splitted_Input_Size+HL_width, HL_width)\n",
        "        if number_HL>22:\n",
        "            self.fc23 = nn.Linear(Splitted_Input_Size+HL_width, HL_width)\n",
        "        if number_HL>23:\n",
        "            self.fc24 = nn.Linear(Splitted_Input_Size+HL_width, HL_width)\n",
        "        if number_HL>24:\n",
        "            self.fc25 = nn.Linear(Splitted_Input_Size+HL_width, HL_width)\n",
        "        if number_HL>25:\n",
        "            self.fc26 = nn.Linear(Splitted_Input_Size+HL_width, HL_width)\n",
        "        if number_HL>26:\n",
        "            self.fc27 = nn.Linear(Splitted_Input_Size+HL_width, HL_width)\n",
        "        if number_HL>27:\n",
        "            self.fc28 = nn.Linear(Splitted_Input_Size+HL_width, HL_width)\n",
        "        if number_HL>28:\n",
        "            self.fc29 = nn.Linear(Splitted_Input_Size+HL_width, HL_width)\n",
        "        if number_HL>29:\n",
        "            self.fc30 = nn.Linear(Splitted_Input_Size+HL_width, HL_width)\n",
        "\n",
        "        self.fcx = nn.Linear(HL_width*number_HL, Output_Size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x_all =x\n",
        "\n",
        "        Splitted_Input_Size = self.fc1.in_features\n",
        "        HL_width = self.fc2.in_features - self.fc1.in_features\n",
        "        number_HL = int(np.round(self.fcx.in_features/HL_width))\n",
        "        length_x_all = number_HL*Splitted_Input_Size\n",
        "\n",
        "        while x_all.size(dim=1) < length_x_all:\n",
        "            x_all = torch.cat([x_all, x],dim=1)\n",
        "\n",
        "        x = self.lru(self.fc1(x_all[:,0:Splitted_Input_Size]))\n",
        "        x_out = x\n",
        "\n",
        "        counter1 = 1\n",
        "        if number_HL>counter1:\n",
        "            x_from_all = x_all[:,Splitted_Input_Size* counter1:Splitted_Input_Size*(counter1+1)]\n",
        "            x = self.lru(self.fc2(torch.cat([x_from_all, x], dim=1)))\n",
        "            x_out = torch.cat([x_out, x], dim=1)\n",
        "\n",
        "        counter1 = counter1 + 1\n",
        "        if number_HL>counter1:\n",
        "            x_from_all = x_all[:,Splitted_Input_Size* counter1:Splitted_Input_Size*(counter1+1)]\n",
        "            x = self.lru(self.fc3(torch.cat([x_from_all, x], dim=1)))\n",
        "            x_out = torch.cat([x_out, x], dim=1)\n",
        "\n",
        "        counter1 = counter1 + 1\n",
        "        if number_HL>counter1:\n",
        "            x_from_all = x_all[:,Splitted_Input_Size* counter1:Splitted_Input_Size*(counter1+1)]\n",
        "            x = self.lru(self.fc4(torch.cat([x_from_all, x], dim=1)))\n",
        "            x_out = torch.cat([x_out, x], dim=1)\n",
        "\n",
        "        counter1 = counter1 + 1\n",
        "        if number_HL>counter1:\n",
        "            x_from_all = x_all[:,Splitted_Input_Size* counter1:Splitted_Input_Size*(counter1+1)]\n",
        "            x = self.lru(self.fc5(torch.cat([x_from_all, x], dim=1)))\n",
        "            x_out = torch.cat([x_out, x], dim=1)\n",
        "\n",
        "        counter1 = counter1 + 1\n",
        "        if number_HL>counter1:\n",
        "            x_from_all = x_all[:,Splitted_Input_Size* counter1:Splitted_Input_Size*(counter1+1)]\n",
        "            x = self.lru(self.fc6(torch.cat([x_from_all, x], dim=1)))\n",
        "            x_out = torch.cat([x_out, x], dim=1)\n",
        "\n",
        "        counter1 = counter1 + 1\n",
        "        if number_HL>counter1:\n",
        "            x_from_all = x_all[:,Splitted_Input_Size* counter1:Splitted_Input_Size*(counter1+1)]\n",
        "            x = self.lru(self.fc7(torch.cat([x_from_all, x], dim=1)))\n",
        "            x_out = torch.cat([x_out, x], dim=1)\n",
        "\n",
        "        counter1 = counter1 + 1\n",
        "        if number_HL>counter1:\n",
        "            x_from_all = x_all[:,Splitted_Input_Size* counter1:Splitted_Input_Size*(counter1+1)]\n",
        "            x = self.lru(self.fc8(torch.cat([x_from_all, x], dim=1)))\n",
        "            x_out = torch.cat([x_out, x], dim=1)\n",
        "\n",
        "        counter1 = counter1 + 1\n",
        "        if number_HL>counter1:\n",
        "            x_from_all = x_all[:,Splitted_Input_Size* counter1:Splitted_Input_Size*(counter1+1)]\n",
        "            x = self.lru(self.fc9(torch.cat([x_from_all, x], dim=1)))\n",
        "            x_out = torch.cat([x_out, x], dim=1)\n",
        "\n",
        "        counter1 = counter1 + 1\n",
        "        if number_HL>counter1:\n",
        "            x_from_all = x_all[:,Splitted_Input_Size* counter1:Splitted_Input_Size*(counter1+1)]\n",
        "            x = self.lru(self.fc10(torch.cat([x_from_all, x], dim=1)))\n",
        "            x_out = torch.cat([x_out, x], dim=1)\n",
        "\n",
        "        counter1 = counter1 + 1\n",
        "        if number_HL>counter1:\n",
        "            x_from_all = x_all[:,Splitted_Input_Size* counter1:Splitted_Input_Size*(counter1+1)]\n",
        "            x = self.lru(self.fc11(torch.cat([x_from_all, x], dim=1)))\n",
        "            x_out = torch.cat([x_out, x], dim=1)\n",
        "\n",
        "        counter1 = counter1 + 1\n",
        "        if number_HL>counter1:\n",
        "            x_from_all = x_all[:,Splitted_Input_Size* counter1:Splitted_Input_Size*(counter1+1)]\n",
        "            x = self.lru(self.fc12(torch.cat([x_from_all, x], dim=1)))\n",
        "            x_out = torch.cat([x_out, x], dim=1)\n",
        "\n",
        "        counter1 = counter1 + 1\n",
        "        if number_HL>counter1:\n",
        "            x_from_all = x_all[:,Splitted_Input_Size* counter1:Splitted_Input_Size*(counter1+1)]\n",
        "            x = self.lru(self.fc13(torch.cat([x_from_all, x], dim=1)))\n",
        "            x_out = torch.cat([x_out, x], dim=1)\n",
        "\n",
        "        counter1 = counter1 + 1\n",
        "        if number_HL>counter1:\n",
        "            x_from_all = x_all[:,Splitted_Input_Size* counter1:Splitted_Input_Size*(counter1+1)]\n",
        "            x = self.lru(self.fc14(torch.cat([x_from_all, x], dim=1)))\n",
        "            x_out = torch.cat([x_out, x], dim=1)\n",
        "\n",
        "        counter1 = counter1 + 1\n",
        "        if number_HL>counter1:\n",
        "            x_from_all = x_all[:,Splitted_Input_Size* counter1:Splitted_Input_Size*(counter1+1)]\n",
        "            x = self.lru(self.fc15(torch.cat([x_from_all, x], dim=1)))\n",
        "            x_out = torch.cat([x_out, x], dim=1)\n",
        "\n",
        "        counter1 = counter1 + 1\n",
        "        if number_HL>counter1:\n",
        "            x_from_all = x_all[:,Splitted_Input_Size* counter1:Splitted_Input_Size*(counter1+1)]\n",
        "            x = self.lru(self.fc16(torch.cat([x_from_all, x], dim=1)))\n",
        "            x_out = torch.cat([x_out, x], dim=1)\n",
        "\n",
        "        counter1 = counter1 + 1\n",
        "        if number_HL>counter1:\n",
        "            x_from_all = x_all[:,Splitted_Input_Size* counter1:Splitted_Input_Size*(counter1+1)]\n",
        "            x = self.lru(self.fc17(torch.cat([x_from_all, x], dim=1)))\n",
        "            x_out = torch.cat([x_out, x], dim=1)\n",
        "\n",
        "        counter1 = counter1 + 1\n",
        "        if number_HL>counter1:\n",
        "            x_from_all = x_all[:,Splitted_Input_Size* counter1:Splitted_Input_Size*(counter1+1)]\n",
        "            x = self.lru(self.fc18(torch.cat([x_from_all, x], dim=1)))\n",
        "            x_out = torch.cat([x_out, x], dim=1)\n",
        "\n",
        "        counter1 = counter1 + 1\n",
        "        if number_HL>counter1:\n",
        "            x_from_all = x_all[:,Splitted_Input_Size* counter1:Splitted_Input_Size*(counter1+1)]\n",
        "            x = self.lru(self.fc19(torch.cat([x_from_all, x], dim=1)))\n",
        "            x_out = torch.cat([x_out, x], dim=1)\n",
        "\n",
        "        counter1 = counter1 + 1\n",
        "        if number_HL>counter1:\n",
        "            x_from_all = x_all[:,Splitted_Input_Size* counter1:Splitted_Input_Size*(counter1+1)]\n",
        "            x = self.lru(self.fc20(torch.cat([x_from_all, x], dim=1)))\n",
        "            x_out = torch.cat([x_out, x], dim=1)\n",
        "        counter1 = counter1 + 1\n",
        "        if number_HL>counter1:\n",
        "            x_from_all = x_all[:,Splitted_Input_Size* counter1:Splitted_Input_Size*(counter1+1)]\n",
        "            x = self.lru(self.fc21(torch.cat([x_from_all, x], dim=1)))\n",
        "            x_out = torch.cat([x_out, x], dim=1)\n",
        "\n",
        "        counter1 = counter1 + 1\n",
        "        if number_HL>counter1:\n",
        "            x_from_all = x_all[:,Splitted_Input_Size* counter1:Splitted_Input_Size*(counter1+1)]\n",
        "            x = self.lru(self.fc22(torch.cat([x_from_all, x], dim=1)))\n",
        "            x_out = torch.cat([x_out, x], dim=1)\n",
        "\n",
        "        counter1 = counter1 + 1\n",
        "        if number_HL>counter1:\n",
        "            x_from_all = x_all[:,Splitted_Input_Size* counter1:Splitted_Input_Size*(counter1+1)]\n",
        "            x = self.lru(self.fc23(torch.cat([x_from_all, x], dim=1)))\n",
        "            x_out = torch.cat([x_out, x], dim=1)\n",
        "\n",
        "        counter1 = counter1 + 1\n",
        "        if number_HL>counter1:\n",
        "            x_from_all = x_all[:,Splitted_Input_Size* counter1:Splitted_Input_Size*(counter1+1)]\n",
        "            x = self.lru(self.fc24(torch.cat([x_from_all, x], dim=1)))\n",
        "            x_out = torch.cat([x_out, x], dim=1)\n",
        "\n",
        "        counter1 = counter1 + 1\n",
        "        if number_HL>counter1:\n",
        "            x_from_all = x_all[:,Splitted_Input_Size* counter1:Splitted_Input_Size*(counter1+1)]\n",
        "            x = self.lru(self.fc25(torch.cat([x_from_all, x], dim=1)))\n",
        "            x_out = torch.cat([x_out, x], dim=1)\n",
        "\n",
        "        counter1 = counter1 + 1\n",
        "        if number_HL>counter1:\n",
        "            x_from_all = x_all[:,Splitted_Input_Size* counter1:Splitted_Input_Size*(counter1+1)]\n",
        "            x = self.lru(self.fc26(torch.cat([x_from_all, x], dim=1)))\n",
        "            x_out = torch.cat([x_out, x], dim=1)\n",
        "\n",
        "        counter1 = counter1 + 1\n",
        "        if number_HL>counter1:\n",
        "            x_from_all = x_all[:,Splitted_Input_Size* counter1:Splitted_Input_Size*(counter1+1)]\n",
        "            x = self.lru(self.fc27(torch.cat([x_from_all, x], dim=1)))\n",
        "            x_out = torch.cat([x_out, x], dim=1)\n",
        "\n",
        "        counter1 = counter1 + 1\n",
        "        if number_HL>counter1:\n",
        "            x_from_all = x_all[:,Splitted_Input_Size* counter1:Splitted_Input_Size*(counter1+1)]\n",
        "            x = self.lru(self.fc28(torch.cat([x_from_all, x], dim=1)))\n",
        "            x_out = torch.cat([x_out, x], dim=1)\n",
        "\n",
        "        counter1 = counter1 + 1\n",
        "        if number_HL>counter1:\n",
        "            x_from_all = x_all[:,Splitted_Input_Size* counter1:Splitted_Input_Size*(counter1+1)]\n",
        "            x = self.lru(self.fc29(torch.cat([x_from_all, x], dim=1)))\n",
        "            x_out = torch.cat([x_out, x], dim=1)\n",
        "\n",
        "        counter1 = counter1 + 1\n",
        "        if number_HL>counter1:\n",
        "            x_from_all = x_all[:,Splitted_Input_Size* counter1:Splitted_Input_Size*(counter1+1)]\n",
        "            x = self.lru(self.fc30(torch.cat([x_from_all, x], dim=1)))\n",
        "            x_out = torch.cat([x_out, x], dim=1)\n",
        "        #print(\"Size before output layer:\",x_out.size(dim=1))\n",
        "        x = self.fcx(x_out)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T1WN1HOYnHAY"
      },
      "outputs": [],
      "source": [
        "def train_model(model, criterion, optimizer, scheduler, train_loader, val_loader, dataset_sizes, device, num_epochs=25):\n",
        "    since = time.time()\n",
        "\n",
        "    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "    best_acc = 0.0\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
        "        print('-' * 10)\n",
        "\n",
        "        model.train() \n",
        "        running_loss = 0.0\n",
        "        running_corrects = 0\n",
        "\n",
        "        for inputs, labels in train_loader:\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            with torch.set_grad_enabled(True):\n",
        "                outputs = model(inputs)\n",
        "                _, preds = torch.max(outputs, 1)\n",
        "                loss = criterion(outputs, labels)\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "\n",
        "            running_loss += loss.item() * inputs.size(0)\n",
        "            running_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "        scheduler.step()\n",
        "\n",
        "        epoch_loss = running_loss / dataset_sizes['train']\n",
        "        epoch_acc = running_corrects.double() / dataset_sizes['train']\n",
        "\n",
        "        print('Train Loss: {:.4f} Acc: {:.4f}'.format(epoch_loss, epoch_acc))\n",
        "\n",
        "        model.eval() \n",
        "        running_loss = 0.0\n",
        "        running_corrects = 0\n",
        "\n",
        "        for inputs, labels in val_loader:\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            with torch.set_grad_enabled(False):\n",
        "                outputs = model(inputs)\n",
        "                _, preds = torch.max(outputs, 1)\n",
        "                loss = criterion(outputs, labels)\n",
        "\n",
        "            running_loss += loss.item() * inputs.size(0)\n",
        "            running_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "        epoch_loss = running_loss / dataset_sizes['valid']\n",
        "        epoch_acc = running_corrects.double() / dataset_sizes['valid']\n",
        "\n",
        "        print('Valid Loss: {:.4f} Acc: {:.4f}'.format(epoch_loss, epoch_acc))\n",
        "\n",
        "        if epoch_acc > best_acc:\n",
        "            best_acc = epoch_acc\n",
        "            best_model_wts = copy.deepcopy(model.state_dict())\n",
        "\n",
        "            print('model save \\n')\n",
        "\n",
        "    time_elapsed = time.time() - since\n",
        "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
        "        time_elapsed // 60, time_elapsed % 60))\n",
        "    print('Best val Acc: {:4f}'.format(best_acc))\n",
        "\n",
        "    model.load_state_dict(best_model_wts)\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CwJs91Bmpday",
        "outputId": "d6edebfa-6a52-4700-c058-13f9c33f8ac0"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "class_weights = compute_class_weight('balanced', classes=np.unique(labels), y=labels)\n",
        "class_weights = torch.tensor(class_weights, dtype=torch.float).to(device)\n",
        "\n",
        "class_weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SLafD42VnIwa"
      },
      "outputs": [],
      "source": [
        "class Mish(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "    def forward(self, x):\n",
        "        return x * torch.tanh(F.softplus(x))\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "dataset_sizes = {\n",
        "    'train': len(train_loader.dataset),\n",
        "    'valid': len(val_loader.dataset),\n",
        "    'all': len(all_loader.dataset)\n",
        "}\n",
        "criterion = nn.CrossEntropyLoss(\n",
        "    weight=class_weights)\n",
        "\n",
        "optimizer_ft = optim.Adam(model_ft.parameters(), lr=0.0001)\n",
        "\n",
        "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=2, gamma=0.01)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dO5f3twdPqyf"
      },
      "outputs": [],
      "source": [
        "def only_train_model(model, criterion, optimizer, scheduler, train_loader, dataset_sizes, device, num_epochs=25):\n",
        "    since = time.time()\n",
        "\n",
        "    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "    best_acc = 0.0\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
        "        print('-' * 10)\n",
        "\n",
        "        # Training phase\n",
        "        model.train()  # Set model to training mode\n",
        "        running_loss = 0.0\n",
        "        running_corrects = 0\n",
        "\n",
        "        for inputs, labels in train_loader:\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # forward and backward\n",
        "            with torch.set_grad_enabled(True):\n",
        "                outputs = model(inputs)\n",
        "                _, preds = torch.max(outputs, 1)\n",
        "                loss = criterion(outputs, labels)\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "\n",
        "            running_loss += loss.item() * inputs.size(0)\n",
        "            running_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "        scheduler.step()\n",
        "\n",
        "        epoch_loss = running_loss / dataset_sizes['all']\n",
        "        epoch_acc = running_corrects.double() / dataset_sizes['all']\n",
        "\n",
        "        print('Train Loss: {:.4f} Acc: {:.4f}'.format(epoch_loss, epoch_acc))\n",
        "\n",
        "        if epoch_acc > best_acc:\n",
        "            best_acc = epoch_acc\n",
        "            best_model_wts = copy.deepcopy(model.state_dict())\n",
        "\n",
        "            print('model save \\n')\n",
        "\n",
        "    time_elapsed = time.time() - since\n",
        "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
        "        time_elapsed // 60, time_elapsed % 60))\n",
        "    print('Best train Acc: {:4f}'.format(best_acc))\n",
        "\n",
        "    model.load_state_dict(best_model_wts)\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PvwR6IP_P_Xf",
        "outputId": "3653d495-42a4-4676-bf4f-c02c1567379b"
      },
      "outputs": [],
      "source": [
        "class_weights = torch.tensor([3,1], dtype=torch.float).to(device)\n",
        "\n",
        "# class_weights = compute_class_weight('balanced', classes=np.unique(labels), y=labels)\n",
        "# class_weights = torch.tensor(class_weights, dtype=torch.float).to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss(\n",
        "    weight=class_weights\n",
        "    )\n",
        "\n",
        "optimizer_ft = optim.Adam(model_ft.parameters(), lr=0.0001)\n",
        "\n",
        "\n",
        "model_ft.fc = SpinalNet(Input_Size = num_ftrs, Number_of_Split=2, HL_width=1024, number_HL=30, Output_Size=2, Activation_Function = Mish())\n",
        "model_ft = model_ft.to(device)\n",
        "\n",
        "# model_ft = only_train_model(model_ft, criterion, optimizer_ft, exp_lr_scheduler, all_loader, dataset_sizes, device, num_epochs=10)\n",
        "model_ft = train_model(model_ft, criterion, optimizer_ft, exp_lr_scheduler, train_loader, val_loader, dataset_sizes, device, num_epochs=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oXkHYrow_Ex2"
      },
      "outputs": [],
      "source": [
        "# 추가 학습\n",
        "# model_ft = only_train_model(model_ft, criterion, optimizer_ft, exp_lr_scheduler, train_loader, dataset_sizes, device, num_epochs=10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iifY8_Ri7nAg"
      },
      "source": [
        "# 변시작"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XT_xRdm97qEc"
      },
      "outputs": [],
      "source": [
        "from torchvision.datasets import VisionDataset\n",
        "from PIL import Image\n",
        "import os\n",
        "from PIL import ImageFile\n",
        "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
        "\n",
        "class SortedImageFolder(VisionDataset):\n",
        "    def __init__(self, root, transform=None):\n",
        "        super(SortedImageFolder, self).__init__(root, transform=transform)\n",
        "        self.images = sorted([os.path.join(root, img) for img in os.listdir(root) if img.endswith(('.png', '.jpg', '.jpeg'))])\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.images)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = self.images[idx]\n",
        "        image = Image.open(img_path).convert(\"RGB\")\n",
        "        if self.transform is not None:\n",
        "            image = self.transform(image)\n",
        "        return image, img_path  # 이미지와 파일 경로를 반환\n",
        "\n",
        "test_data_path = '/content/drive/MyDrive/Colab Notebooks/2023_HD_DT_2/2023-uou-hd-dt-2-cv/new_test/test'\n",
        "\n",
        "\n",
        "test_transform = transforms.Compose([\n",
        "    transforms.Resize((256, 256)),\n",
        "    # transforms.Grayscale(num_output_channels=1),\n",
        "    transforms.ToTensor(),\n",
        "    # transforms.Normalize(mean=[0.48145466, 0.4578275, 0.40821073] , std=[0.26862954, 0.26130258, 0.27577711])\n",
        "    # transforms.Normalize((0.487), (0.267))\n",
        "])\n",
        "\n",
        "# 데이터셋 및 데이터 로더 설정\n",
        "test_dataset = SortedImageFolder(root=test_data_path, transform=test_transform)\n",
        "test_loader = DataLoader(test_dataset, batch_size=128, shuffle=False)\n",
        "\n",
        "# 모델을 평가 모드로 설정\n",
        "model_ft.eval()\n",
        "\n",
        "# 예측 결과를 저장할 리스트\n",
        "predictions = []\n",
        "\n",
        "# 테스트 데이터에 대해 예측 수행\n",
        "with torch.no_grad():\n",
        "    for inputs, paths in test_loader:\n",
        "        inputs = inputs.to(device)\n",
        "        outputs = model_ft(inputs)\n",
        "        _, preds = torch.max(outputs, 1)\n",
        "        predictions.extend(zip(paths, preds.cpu().numpy()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CLqxJjSR7rWo",
        "outputId": "f4a1fac6-791d-4a6c-ebca-03d35ef2b558"
      },
      "outputs": [],
      "source": [
        "preds = []\n",
        "\n",
        "# 파일 이름에 따라 정렬된 예측 결과 출력\n",
        "for path, pred in sorted(predictions, key=lambda x: int(os.path.basename(x[0]).split('.')[0])):\n",
        "    # print(f'File: {os.path.basename(path)}, Prediction: {pred}')\n",
        "    preds.append(pred)\n",
        "\n",
        "preds.count(0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N73pVydj7tGJ"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "submit = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/2023_HD_DT_2/2023-uou-hd-dt-2-cv/sample_submission.csv')\n",
        "submit.iloc[:, 1] = preds\n",
        "\n",
        "submit.to_csv('/content/drive/MyDrive/Colab Notebooks/2023_HD_DT_2/2023-uou-hd-dt-2-cv/result/submit_1.csv', index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z15sakRb7o3Y"
      },
      "source": [
        "# 변끝"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 410
        },
        "id": "jxG2BfQtzg-R",
        "outputId": "44a051e0-5202-4c95-863c-e7595bac042e"
      },
      "outputs": [],
      "source": [
        "from torchvision.datasets import VisionDataset\n",
        "from PIL import Image\n",
        "import os\n",
        "from PIL import ImageFile\n",
        "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
        "\n",
        "class SortedImageFolder(VisionDataset):\n",
        "    def __init__(self, root, transform=None):\n",
        "        super(SortedImageFolder, self).__init__(root, transform=transform)\n",
        "        self.images = sorted([os.path.join(root, img) for img in os.listdir(root) if img.endswith(('.png', '.jpg', '.jpeg'))])\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.images)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = self.images[idx]\n",
        "        image = Image.open(img_path).convert(\"RGB\")\n",
        "        if self.transform is not None:\n",
        "            image = self.transform(image)\n",
        "        return image, img_path  # 이미지와 파일 경로를 반환\n",
        "\n",
        "test_data_path = '/content/drive/MyDrive/Pre_processing/test'\n",
        "\n",
        "\n",
        "test_transform = transforms.Compose([\n",
        "    transforms.Resize((256, 256)),\n",
        "    # transforms.Grayscale(num_output_channels=1),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.48145466, 0.4578275, 0.40821073] , std=[0.26862954, 0.26130258, 0.27577711])\n",
        "    # transforms.Normalize((0.487), (0.267))\n",
        "])\n",
        "\n",
        "# 데이터셋 및 데이터 로더 설정\n",
        "test_dataset = SortedImageFolder(root=test_data_path, transform=test_transform)\n",
        "test_loader = DataLoader(test_dataset, batch_size=128, shuffle=False)\n",
        "\n",
        "# 모델을 평가 모드로 설정\n",
        "model_ft.eval()\n",
        "\n",
        "# # 예측 결과를 저장할 리스트\n",
        "# predictions = []\n",
        "\n",
        "# # 테스트 데이터에 대해 예측 수행\n",
        "# with torch.no_grad():\n",
        "#     for inputs, paths in test_loader:\n",
        "#         inputs = inputs.to(device)\n",
        "#         outputs = model_ft(inputs)\n",
        "#         _, preds = torch.max(outputs, 1)\n",
        "#         predictions.extend(zip(paths, preds.cpu().numpy()))\n",
        "\n",
        "# 예측 확률을 저장할 리스트\n",
        "predictions_probs = []\n",
        "\n",
        "# 테스트 데이터에 대해 예측 수행\n",
        "with torch.no_grad():\n",
        "    for inputs, paths in test_loader:\n",
        "        inputs = inputs.to(device)\n",
        "        outputs = model_ft(inputs)\n",
        "\n",
        "        # softmax를 사용하여 확률로 변환\n",
        "        probs = F.softmax(outputs, dim=1)\n",
        "        predictions_probs.extend(zip(paths, probs.cpu().numpy()))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CGVj4SaAzrEB"
      },
      "outputs": [],
      "source": [
        "# 클래스 0의 확률을 추출하고 (파일 경로, 확률) 쌍을 저장\n",
        "class_zero_probs = [(path, prob[0]) for path, prob in predictions_probs]\n",
        "\n",
        "# 확률에 따라 내림차순으로 정렬\n",
        "class_zero_probs.sort(key=lambda x: x[1], reverse=True)\n",
        "\n",
        "# 상위 970개 샘플 선택\n",
        "selected_for_class_zero = set([path for path, _ in class_zero_probs[:970]])\n",
        "\n",
        "# 최종 예측 결과 생성\n",
        "final_predictions = [(path, 0 if path in selected_for_class_zero else 1) for path, _ in predictions_probs]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5PMOU-p9zr3x"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# final_predictions에서 파일 경로와 예측값 추출\n",
        "file_paths, preds = zip(*final_predictions)\n",
        "\n",
        "# 파일명만 추출 (전체 경로에서 파일명만 필요하다면)\n",
        "file_names = [os.path.basename(path) for path in file_paths]\n",
        "\n",
        "# DataFrame 생성\n",
        "submit_df = pd.DataFrame({'Id': file_names, 'Class': preds})\n",
        "\n",
        "# CSV 파일로 저장\n",
        "submit_df.to_csv('/content/drive/MyDrive/Colab Notebooks/2023_HD_DT_2/2023-uou-hd-dt-2-cv/submit39.csv', index=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G_iikziizs4B",
        "outputId": "426687a5-64ca-4889-ea9b-bbc02cb550f7"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# CSV 파일 읽기\n",
        "submit_df = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/2023_HD_DT_2/2023-uou-hd-dt-2-cv/submit39.csv')\n",
        "\n",
        "# 'Id' 컬럼에서 '.jpg' 제거하고 정수로 변환\n",
        "submit_df['Id'] = submit_df['Id'].str.replace('.jpg', '').astype(int)\n",
        "\n",
        "# 내림차순으로 정렬\n",
        "submit_df = submit_df.sort_values(by='Id', ascending=True)\n",
        "\n",
        "# 정렬된 DataFrame을 다시 CSV 파일로 저장\n",
        "submit_df.to_csv('/content/drive/MyDrive/Colab Notebooks/2023_HD_DT_2/2023-uou-hd-dt-2-cv/submit39.csv', index=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "68_Y8FM40Ym3",
        "outputId": "7ca84d7a-61fc-4a77-ae12-d1b14b45eca8"
      },
      "outputs": [],
      "source": [
        "preds = []\n",
        "\n",
        "for path, pred in sorted(predictions, key=lambda x: int(os.path.basename(x[0]).split('.')[0])):\n",
        "    preds.append(pred)\n",
        "\n",
        "preds.count(0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NuL11ML-0ZTQ",
        "outputId": "ba1af56e-b45a-411e-def8-2a7b72b157fd"
      },
      "outputs": [],
      "source": [
        "preds.count(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tAlhFVfR0aP1"
      },
      "outputs": [],
      "source": [
        "submit = pd.read_csv('/sample_submission.csv')\n",
        "submit.iloc[:, 1] = preds\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gbYbSpYg0bV-"
      },
      "outputs": [],
      "source": [
        "submit.to_csv('/submit.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QTdyctUHSWUV"
      },
      "outputs": [],
      "source": [
        "# torch.save(model_ft.state_dict(), '/content/drive/MyDrive/Colab Notebooks/2023_HD_DT_2/2023-uou-hd-dt-2-cv/result/model21.pt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FF-9LWsCWoJM"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
